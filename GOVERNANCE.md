# Official AI Policy & Safety Reference Archive

This document provides a curated collection of authoritative links to the official ethical, safety, and operational guidelines governing the current generative AI ecosystem. These sources represent the "ground truth" for model alignment and compliance.

---

## ðŸ›¡ï¸ Google & Gemini Ecosystem

As the primary architect of the Gemini models, Google maintains several living documents regarding safety and responsibility.

* **[Google AI Principles](https://ai.google/responsibility/principles/)**
    *The foundational ethical framework for all Google AI development, updated to reflect the "Bold and Responsible" 2026 stance.*
* **[Gemini Safety Guidelines (Developer)](https://ai.google.dev/gemini-api/docs/safety-guidelines)**
    *Technical documentation for setting safety thresholds, handling 'redlines', and managing content filters in the Gemini API.*
* **[Google AI Responsibility Reports](https://ai.google/responsibility/responsibility-reports/)**
    *Annual and mid-year transparency reports (including the February 2025/2026 releases) documenting real-world safety performance.*
* **[Generative AI Prohibited Use Policy](https://policies.google.com/terms/generative-ai/use-policy)**
    *The official legal boundaries for what users and developers can and cannot do with Googleâ€™s generative models.*

---

## ðŸŒ Industry Standards & Cross-Model Safety

These links provide the broader context for AI safety standards across the industry.

* **[OpenAI Safety & Responsibility](https://openai.com/safety)**
    *The official hub for OpenAIâ€™s safety standards, including their Frontier Risk Framework.*
* **[NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)**
    *The gold-standard government framework (US) used by major labs to benchmark AI safety and security.*
* **[The Frontier Model Forum](https://www.frontiermodelforum.org/)**
    *An industry body focused on the safe development of frontier AI models, founded by Google, OpenAI, Anthropic, and Microsoft.*

---

## ðŸ› ï¸ Developer Resources & Tools

Tools for auditing and implementing the policies found in the links above.

* **[Responsible Generative AI Toolkit](https://ai.google.dev/responsible)**
    *Google's open-source tools for safety evaluation and model alignment.*
* **[ML Commons: AI Safety Benchmarking](https://mlcommons.org/en/groups/ai-safety/)**
    *A collaborative effort to create standardized safety tests for LLMs.*

---

> **Note:** This list is intended for educational and documentary purposes. For production-level compliance, always refer to the specific Terms of Service provided by the API vendor.
